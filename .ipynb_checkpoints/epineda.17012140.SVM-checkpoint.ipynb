{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nombreNotebook.JPG](img/nombreNotebook.JPG)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 6 - Support Vector Machine\n",
    "\n",
    "Support vector machines es un algoritmo de clasificacion, basicamente lo que busca es la mejor manera de separar la data. Para ellos, hacemos uso del concepto de frontera de decision. En nuestro caso para SVM utilizamos la frontera de decision con cierto margen entre la frontera que divide a un grupo de otro.\n",
    "\n",
    "Este \"margen\" o división por medio de líneas se puede definir de la siguiente manera:   \n",
    " * La distancia entre el vector de soporte y la las lineas que forman la frontera es tan grande como sea posible.\n",
    "\n",
    "\n",
    "Como maximizamos el margen que conforma la frontera? Este es un problema de optimizacion con restricciones (Constrained optimization problem). \n",
    "\n",
    "* Limitacion: Los puntos al final de los vectores de soporte no pueden estar dentro del margen de frontera. \n",
    "* Optimizacion: El margen de frontera debe ser tan grande como sea posible.\n",
    "\n",
    "## ¿Cómo se optimiza?\n",
    "\n",
    "Para este caso, utlizamos Multiplicadores de Lagrange \n",
    "\n",
    "\n",
    "1. Buscar/adquirir la data \n",
    "2. Aplicar un model\n",
    "\n",
    "\n",
    "Parametro C:  \n",
    "Que pasa cuando tenemos un ejemplo que se sale del orden de clasificacion (missclasification)\n",
    "\n",
    "Paramtro C:  \n",
    "Que tanto se tiene que penalizar este tipo de error de clasificacion. El parametro default para el parametro C es uno.\n",
    "\n",
    "Low C:   \n",
    "Prioritize simplicity\n",
    "\n",
    "High C:   \n",
    "Prioriteze makeing few mistakes (overfitting). Esto es un hiperparametro.\n",
    "\n",
    "**Que pasa si necesitamos mas de dos clases? Funciona?**\n",
    "\n",
    "Si, pero la frontera de decision es unicamente lineas. (para fronteras de decision mas complejas, debemos utilizar feature engineering).\n",
    "\n",
    "Cuando se trata de un problema de clasificacion que no es binario (cuando el resultado de la clasificacion no es una variable dicotomica). Se pueden utilizar dos tipos de tecnicas: \n",
    "\n",
    "* One vs Rest\n",
    "* One vs One\n",
    "\n",
    "## Kernel trick: Visual \n",
    "\n",
    "Para fronteras de decision no lineales.  Lo que hace es agregar otra dimension a la data, para tratar de poder trazar una frontera de division a travez de un hiperplano que si pueda realizar la clasificacion con una frontera de decision lineal\n",
    "\n",
    "**Otro hiperparametro** Gamma value: A mayor gamma, mayor complejidad, por tanto se corre riesgo de overfitting.\n",
    "\n",
    "\n",
    "¿Cómo se entrena? y otros detalles\n",
    "Hipotesis\n",
    "\n",
    "Se optimiza la siguiente función:  \n",
    "![f1.jpg](img/f1.jpg)  \n",
    "\n",
    "o también se puede optimizar si se tiene la siguiente forma:  \n",
    "\n",
    "![f2.jpg](img/f2.jpg)  \n",
    "\n",
    "Función Final después de reducir a su máxima expresión la función:  \n",
    "\n",
    "![ff.jpg](img/ff.jpg)  \n",
    "\n",
    "## ¿Predicción o Inferencia?\n",
    "\n",
    "El algoritmo SVM puede emplearse para fines de clasificacion y regresion de dos grupos de datos, comprende una maquina de soporte vectorial para la clasificacion (SVM) y una de regresion (SVR), dado un conjunto de ejemplos de entrenamiento que pertenecen a una de dos categorías, SVM construye un modelo que predice si un ejemplo cae dentro de una u otra categoría, la salidas son valores entre el rango [-1,1]\n",
    "\n",
    "![fpred.jpg](img/fpred.jpg)   \n",
    "\n",
    "\n",
    "\n",
    "## Diferencias:\n",
    "Una de las principales diferencias entre este metodo de clasificacion y el de KNN visto en clase, es que éste es un metodo parametrico por lo que si requiere de un proceso de entrenamiento.\n",
    "\n",
    "Contrario al algoritmo de regresion logistica (otro modelo de clasificación que si es parametrico), este modelo no nos brinda una distribucion de probabilidad en cuanto al valor de la variable a predecir.\n",
    "\n",
    "\n",
    "\n",
    "## ¿Ventajas?\n",
    "Funciona bien para datos linealmente separables, para datos que son casi linealmente separables puede funcionar bien con el valor correcto del hiperplano.\n",
    "Para datos que no son separables linealmente podemos proyectar los datos al espacio donde es perfectamente o casi linealmente separable.\n",
    "SVM tiene la ventaja de poder manejar multiples dimensiones correctamente\n",
    "Prediccion rapida porque solamente usa un subconjunto de datos ya que maximiza la distancia entre los puntos mas cercanos entre las dos clases\n",
    "El algoritmo se adapta a los datos, no es necesario buscar otro algoritmo o ecuacion como en la regresion lineal, las bandas o rangos tienen el mismo comportamiento que la curva para abarcar la mayor cantidad de datos.\n",
    "\n",
    "![kernel.JPG](img/kernel.JPG)   \n",
    "\n",
    "## ¿Desventajas?\n",
    "El algoritmo funciona muy bien solamente cuando tiene datos limpios\n",
    "No es una desventaja pero sí una limitación es que se debe escoger correctamente el kernel a usar para obtener buenos resultados\n",
    "Si hay datos muy dispersos estos seran discriminados\n",
    "\n",
    "\n",
    "## Conclusiones\n",
    "\n",
    " * La tecnica es efectiva en espacios de alta dimensión.\n",
    " * Utiliza un subconjunto de puntos de entrenamiento en la función de decisión (llamados vectores de soporte), por lo que también es eficiente en la memoria.\n",
    " * SVM difiere de los otros algoritmos de clasificación en la forma en que elige el límite de decisión que maximiza la distancia desde los puntos de datos más cercanos de todas las clases.\n",
    " * El algoritmo genera un hiperplano óptimo que categoriza nuevos ejemplos.\n",
    " \n",
    "\n",
    "\n",
    "## Bibliografias:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/svm.html\n",
    "https://www.geeksforgeeks.org/classifying-data-using-support-vector-machinessvms-in-python/\n",
    "https://www.cienciadedatos.net/documentos/34_maquinas_de_vector_soporte_support_vector_machines\n",
    "https://www.youtube.com/watch?v=Y6RRHw9uN9o\n",
    "https://www.youtube.com/watch?v=N1vOgolbjSc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
